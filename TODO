- Add NaN and Inf catching to key places in code

- Make multi-threaded rendering scale:
	- Modify grid tracing code to take a list of rays, and only pull geometry from the cache
	  once per set of rays.

- More compact and/or faster top-level BVH:
	- More compact probably actually doesn't matter so much, given
	  the intended usage of Psychopath.  The top-level BVH is likely
	  to be relatively sparse anyway compared to most path tracers,
	  since it uses higher-order surface descriptions.  Focus on speed.
	- Four basic approaches to speeding up traversal:
		- Reducing the number of nodes traversed on average
		- Reducing the cost of testing against each node
		- Using SIMD to test multiple nodes at once
		- Improving cache coherency of traversal by better tree layout
	- Create a custom BBox type that contains two BBoxes each, one for each child.
	  Make its data layout SIMD friendly both for interpolation and for
	  intersection testing.  This will be useful for scaling up to a QBVH as well.
	- Organize BBox array so that the first child directly follows the parent,
	  for better cache coherency.
	- Does sticking the BBoxes directly in the node structures make sense?  How
	  will that impact walking up the tree in terms of cache coherency?
	- What about putting sibling indexes in the nodes, to avoid round-trip with
	  the parent to find sibling nodes?

- Change MicroSurface to use implicit indexing for its BVH.
	- Also play with making the nodes cubes, so that the volume can be stored
	  as four floats instead of six.
	- QBVH for MicroSurface, also with implicit indexing

- MicroSurface should calculate normal and point differentials for
  ray intersections.
	- What is the minimum amount of data we need to store to calculate
	  this efficiently?
		- We can assume grids for now.  If we need to lift that
		  assumption in the future, we can deal with that then.
		- Goal is to keep things compact.  How much can we quantize
		  things, especially if we limit grid size?
			- UV's are always regular, so we can quantize them without
			  it even being lossy.
			- Quantizing normals might work if we still interpolate
			  in unquantized values.
		- Is there some innovative way to calculate good-enough
		  approximations based on the bounding boxes themselves?

- Investigate ray differential corner-cases:
	- Rays that are nearly tangent to the surfaces they intersect
	- Given that surfaces are approximated with bounding boxes,
	  chances of a ray hitting a surface at tangent angle is
	  non-zero.  That should be handled somehow.
		- Probabilistic misses based on incident angle...?  Would likely
		  creating tunneling--how to handle that?  Would it be a problem
		  in practice?

- Implement a basic shading system that does proper ray differential
  propigation, so that the code for that is all in one convenient
  place.
	- A differential geometry class would be very useful for this.

- Framework for surface primitives to manage their splitting and micropolygons
  in a thread-safe way.
	- Should be generic enough for all surface primitives to use.
	- Perhaps define an API that primitives must expose, which the framework
	  can use.
	- How can this relate to a bigger picture that handles, e.g.,
	  particles, curves, and volumes as well?

- Surface primitive API:
	- separate() -- separates out natural component primitives that
	                together make up the original.  Used on scene
	                loading to make sure everything can be handled
	                by the surface framework.
	- split() -- splits the primitive into multiple primitives that
	             together make up the original.  May be called on scene
	             loading, but is primarily for the tracing stages.
	- micro_estimate() -- given a target microelement size, estimates
	                      the number of microelements that would have to
	                      be generated to achieve it.
	- micro_generate() -- generates the MicroSurface





- Migrate all render configuration data to Renderer

- Simple scene-description format

- Adaptive sampling scheme
	//- Calculate variance information per pixel
	- Reduce the Sampler's responsibilities, migrating pixel/sample
	  traversal to be the Integrator's responsibilitiy.
	- Implement adaptive sample traversal based on variance

- Refactor TimeBox template to use class methods for interpolation

- OSL integration

//- Faster sorting of potential ray intersections
	//- Counting sort
		- Big benefit of counting sort is we automatically get the starting
		  indices in the potential intersections array for each object.
		- http://www.drdobbs.com/architecture-and-design/parallel-counting-sort/224700144
		- http://www.drdobbs.com/parallel/parallel-counting-sort-part-2/225900071

